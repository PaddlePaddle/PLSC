# PLSC: PaddlePaddle大规模分类库

## 简介
PaddlePaddle大规模分类库(PLSC: PaddlePaddle Large Scale Classification)是
基于[飞桨平台](https://www.paddlepaddle.org.cn)构建的超大规模分类库，为用
户提供从训练到部署的大规模分类问题全流程解决方案。

深度学习中用于解决多分类问题的深度神经网络的最后一层通常是全连接层+Softmax，
并采用交叉熵(Cross-Entropy)算法计算网络的损失函数。由于全连接层的参数量随着
分类类别数的增长线性增长，当分类类别数相当大时，会面临下面两个主要挑战：

1. 参数量过大，超出单个GPU卡的显存容量：假设分类网络最后一层隐层的输出维度为512，
那么当分类类别数为一百万时，最后一层全连接层参数的大小约为2GB（假设以32比特浮点
数表示参数）。当分类问题的类别数为一亿时（例如，对自然界中的生物进行分类），则
最后一层全连接层参数的大小接近200GB，远远超过当前GPU的显存容量。

2. 参数量较大，同步训练方式下通信开销较大：数据并行训练方式下，所有GPU卡之间需
要同步参数的梯度信息，以完成参数值的同步更新。当参数数量较大时，参数的梯度信息
数据量同样较大，从而导致参数梯度信息的通信开销较大，影响训练速度。

为了解决大规模分类问题，我们设计开发了PaddlePaddle大规模分类库PLCS，为用户提供
从训练到部署的大规模分类问题全流程解决方案。

## 设计思想

解决大规模分类问题的核心思想是采用模型并行方案实现深度神经网络模型的全连接层以
及之后的损失值计算。

首先，我们回顾大规模分类问题面临的两个主要挑战：

1. 参数量过大，超出单个GPU卡的显存容量

2. 参数量较大，同步训练方式下通信开销较大

### 显存优化

为了解决显存不足的问题，PLSC采用模型并行设计，将深度神经网络的最后一层全连接层切
分到各个GPU卡。全连接层天然地具有可切分属性，无外乎是一个矩阵乘法和加法（存在偏置
项的情形下）。假设以100张GPU卡进行模型训练，当分类类别数目为一亿时，每张GPU卡上的
全连接参数的大小约为2GB，这完全是可接受的。

对于全连接层计算，可以表示为矩阵乘法和加法，如下面的公示所示：

![FC计算公示](images/fc_computing.png)

其中，_W_和_b_全连接层参数，_X_是神经网络最后一层隐层的输出。将根据矩阵分块原理，全
连接层计算又可以进一步地表示为下面的形式：

![FC计算公示展开](images/fc_computing_block.png)


PLSC具备以下特点：

- 基于源于产业实践的开源深度学习平台[飞桨平台](https://www.paddlepaddle.org.cn)
- 包含大量的预训练模型 (TBD)
- 提供从训练到部署的全流程解决方案 (TBD)

## 使用教程

我们提供了一系列使用教程，来帮助用户完成使用PLSC大规模分类库进行训练、评估和部署。

这一系列文档分为__快速入门__、__基础功能__、__预测部署__和__高级功能__四个部分，由浅入深地介绍PLSC大规模分类库的设计思路和使用方法。

### 快速入门

* [安装说明](docs/installation.md)
* [训练/评估/部署](docs/usage.md)

### 基础功能

* [API简介](docs/api_intro.md)
* [自定义模型](docs/custom_models.md)
* [自定义Reader接口]

### 预测部署

* [模型导出](docs/export_for_infer.md)
* [C++预测库使用]

### 高级功能

* [分布式参数转换](docs/distributed_params.md)
* [Base64格式图像预处理](docs/base64_preprocessor.md)
